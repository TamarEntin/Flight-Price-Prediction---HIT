{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0c69c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae3de74",
   "metadata": {},
   "source": [
    "<html>\n",
    "<style>\n",
    "        table, th, td {\n",
    "        border:1px solid black;\n",
    "        }\n",
    "</style>\n",
    "    <body>\n",
    "        <h1>The Data Crawling Part</h1>\n",
    "        <hr>\n",
    "        <p>In this Part we are going to collect our data.</p>\n",
    "        <p>The crawling is a selenium crawling from the 'www.il.kayak.com' website.</p>\n",
    "        <p>The data will be as the table below:</p>\n",
    "        <table>\n",
    "        <tr>\n",
    "            <th>Airline</th>\n",
    "            <th>Date</th>\n",
    "            <th>Source_Airport</th>\n",
    "            <th>Destination_Airport</th>\n",
    "            <th>Route</th>\n",
    "            <th>Departure_Time</th>\n",
    "            <th>Arrival_Time</th>\n",
    "            <th>Duration</th>\n",
    "            <th>Stops_Number</th>\n",
    "            <th>Price</th>\n",
    "        </tr>\n",
    "        <tr>\n",
    "            <th>...</th>\n",
    "            <th>...</th>\n",
    "            <th>...</th>\n",
    "            <th>...</th>\n",
    "            <th>...</th>\n",
    "            <th>...</th>\n",
    "            <th>...</th>\n",
    "            <th>...</th>\n",
    "            <th>...</th>\n",
    "            <th>...</th>\n",
    "        </tr>\n",
    "        </table>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47b3dad",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>open_web</h>\n",
    "        <hr>\n",
    "        <p>Open web is a function that gets departure country(dep_country), the destination country(des_country), departure date(dep_date), ticket type (category) - there are three ticket search in the website - Cheapest/Best/Quickest\n",
    "            and finally the web driver - we use the chrome driver.</p>\n",
    "        <p></p>\n",
    "        <p>This function builds a url from the parameters it gets, and commands the driver to open the webpage.</p>\n",
    "        <p>**&fs=legdur=-600;airlines=-MULT,flylocal - defines the airlines not to be multiple, and that duration will be until 10h</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63b699f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_web(dep_country, des_country, dep_date, category,driver):\n",
    "    url = ('https://www.il.kayak.com/flights/' + dep_country + '-' + des_country + '/' +\n",
    "          dep_date + '/?sort=' + category + '&fs=legdur=-600'+ ';airlines=-MULT,flylocal')\n",
    "    driver.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f1f2b2",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>more_button</h>\n",
    "        <hr>\n",
    "        <p>when we search for tickets in the kayak website there is a button 'Show more results', more_button function is a function that gets the clicking number on this button parameter(more_results_button) - that will command the driver click on this button 'number times'</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b125369",
   "metadata": {},
   "outputs": [],
   "source": [
    "def more_button(more_results_button,driver):\n",
    "    for i in range(more_results_button):\n",
    "        try:\n",
    "            time.sleep(1.5)\n",
    "            driver.find_element_by_xpath('//a[@class=\"moreButton\"]').click()\n",
    "        except:\n",
    "            time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed20e70",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>try_except_of_xpath</h>\n",
    "        <hr>\n",
    "        <p>When we need to get elements we need to the webpage be opened.</p>\n",
    "        <p>This function gets xpath of the elements we must collect and two different times - normal and critical.</p>\n",
    "        <p>the code will wait normal_time time, then gets the elements, sometimes the webpage takes more seconds to be loaded,\n",
    "            so if the normal_time waiting is going to get error, we will wait another cirical_time time and then collect the elements.</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4d4c24b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_except_of_xpath(normal_time, critical_time, xpath, driver):\n",
    "    try:\n",
    "        time.sleep(normal_time)\n",
    "        element = driver.find_elements_by_xpath(xpath)\n",
    "    except:\n",
    "        time.sleep(critical_time)\n",
    "        element = driver.find_elements_by_xpath(xpath)\n",
    "    finally:\n",
    "        return element"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6124662",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>Get_Times</h>\n",
    "        <hr>\n",
    "        <p>When the webpage is opened we gets depart and arrival times element, collecting the text from them into two lists.</p>\n",
    "        <p>.</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22a95c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Times(driver):\n",
    "    Depart_elements = try_except_of_xpath(0.5,2,'\\\n",
    "    //span[@class=\"depart-time base-time\"]',driver)\n",
    "    Arrival_elements = try_except_of_xpath(0.5,2,'\\\n",
    "    //span[@class=\"arrival-time base-time\"]',driver)\n",
    "    Departure_Time = []\n",
    "    Arrival_Time = []\n",
    "    for i in range(len(Depart_elements)):\n",
    "        Departure_Time.append(Depart_elements[i].text)\n",
    "        Arrival_Time.append(Arrival_elements[i].text)\n",
    "    return Departure_Time, Arrival_Time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60196704",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>Get_Durations</h>\n",
    "        <hr>\n",
    "        <p>When the webpage is opened we gets duration element, collecting the text from them into two lists.</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f40fc6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Durations(driver):\n",
    "    durations = try_except_of_xpath(0.5,2, '\\\n",
    "    //div[@class=\"section duration allow-multi-modal-icons\"]\\\n",
    "    /div[@class=\"top\"]',driver)\n",
    "    Duration = []\n",
    "    for i in range(len(durations)):\n",
    "        Duration.append(durations[i].text)\n",
    "    return Duration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996ef4b6",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>Get_Airport_by_3_letters</h>\n",
    "        <hr>\n",
    "        <p>This function gets a raw test of an airport and takes the first three letters of it.</p>\n",
    "        <p>For example: (raw_airport = 'TLV Ben Gurion int') and turns this into (airport = 'TLV')</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7580e130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Airport_by_3_letters(raw_airport):\n",
    "    pattern = '(\\w\\w\\w) .*'\n",
    "    airport = re.findall(pattern,raw_airport)[0]\n",
    "    return airport"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361e1623",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>Get_Airports</h>\n",
    "        <hr>\n",
    "        <p>When the webpage is opened we get by one xpath the source and the destination airport elements. Then we must separate them into two lists and get the 3 first letters of the airport name (Get_Airport_by_3_letters function) .</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d919f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Airports(driver):\n",
    "    airports = try_except_of_xpath(0.5,2, '//span[@class=\"airport-name\"]',driver)\n",
    "    Source_Airports = []\n",
    "    Destination_Airports = []\n",
    "    for i in range(len(airports)//2):\n",
    "        try:\n",
    "            airport = airports[2*i].text\n",
    "            Source_Airports.append(Get_Airport_by_3_letters(airport))\n",
    "        except:\n",
    "            Source_Airports.append(np.nan)\n",
    "        try:\n",
    "            airport = airports[1+2*i].text\n",
    "            Destination_Airports.append(Get_Airport_by_3_letters(airport))\n",
    "        except:\n",
    "            Destination_Airports.append(np.nan)\n",
    "    return Source_Airports, Destination_Airports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d2cb2a",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>Get_Stops</h>\n",
    "        <hr>\n",
    "        <p>When the webpage is opened we get the number of stops, and the stops elements. After this we collect the text from those elements.</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4326ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Stops(driver):\n",
    "    stops_num = try_except_of_xpath(0.5,2, '\\\n",
    "    //div[@class=\"section stops\"]/div[@class=\"top\"]',driver)\n",
    "    stops_cities = try_except_of_xpath(0.5,2, '\\\n",
    "    //div[@class=\"section stops\"]/div[@class=\"bottom\"]',driver)\n",
    "    Stops_Number = []\n",
    "    Route = []\n",
    "    for i in range(len(stops_num)):\n",
    "        Stops_Number.append(stops_num[i].text)\n",
    "        Route.append(stops_cities[i].text)\n",
    "    return Stops_Number, Route"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b64aa7a",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>Get_Price</h>\n",
    "        <hr>\n",
    "        <p>When the webpage is opened we get the Price elements. After this we collect the text from those elements.</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3c88832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Price(driver):\n",
    "    ticket_price = try_except_of_xpath(0.5,2, '\\\n",
    "    //div[@class=\"booking\"]//span[@class=\"price-text\"]',driver)\n",
    "    Price = []\n",
    "    for ticket in ticket_price:\n",
    "        Price.append(ticket.text[1:])\n",
    "    return Price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d10380",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>Get_Airlines</h>\n",
    "        <hr>\n",
    "        <p>When the webpage is opened we get the Airline elements. After this we collect the text from those elements.</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad33eedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Airlines(driver):\n",
    "    airline = try_except_of_xpath(0.5,2,'\\\n",
    "    //div[@class=\"section codeshares allow-airlines\"]/\\\n",
    "    span[@class=\"codeshares-airline-names\"]',driver)\n",
    "    Airlines = []\n",
    "    for line in airline:\n",
    "        Airlines.append(line.text)\n",
    "    return Airlines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799df93c",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>crawl_page</h>\n",
    "        <hr>\n",
    "        <p>This function takes the the lists of the ticket data, by each function we described before. And returns a list of lists of the data we collected.</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4d3647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_page(driver):\n",
    "    # getting list of the times of each flight (departure and arrival)\n",
    "    time.sleep(1)\n",
    "    Departure_Time, Arrival_Time = Get_Times(driver)\n",
    "    # getting list of the durations of each flight\n",
    "    time.sleep(1)\n",
    "    Durations = Get_Durations(driver)\n",
    "    # getting list of the airports we departure and arrive\n",
    "    time.sleep(1)\n",
    "    Source_Airport, Destination_Airport = Get_Airports(driver)\n",
    "    # getting list of number and places of stops\n",
    "    time.sleep(1)\n",
    "    Stops_Number, Route = Get_Stops(driver)\n",
    "    # getting the prices of the flights\n",
    "    time.sleep(1)\n",
    "    Price = Get_Price(driver)\n",
    "    # getting the airlines of the flights\n",
    "    time.sleep(1)\n",
    "    Airlines = Get_Airlines(driver)\n",
    "    return [Airlines, Source_Airport, Destination_Airport, Route, Departure_Time, Arrival_Time, Durations, \n",
    "           Stops_Number, Price]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd64449a",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>Write_CSV</h>\n",
    "        <hr>\n",
    "        <p>Sometimes the crawling data can be interupted and stoped by internet,electricity causes and etc...</p>\n",
    "        <p>So it be easier to begin the process from the point we stopped and not to begin itself from the start. This why we save each page into our data</p>\n",
    "        <p>This function recives a dictionary for the page tickets data we crawled, creates from it a df, and saves it with the other data we collected before.</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fce1f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Write_CSV(normal_page_dic):\n",
    "    try:\n",
    "        Df = pd.DataFrame(normal_page_dic)\n",
    "        Saved_DF = pd.read_csv('Crawled_Data.csv')\n",
    "        New_df = pd.concat([Saved_DF,Df])\n",
    "        New_df.to_csv('Crawled_Data.csv',index=False)\n",
    "    except:\n",
    "        Df.to_csv('Crawled_Data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d37ae3d",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>Crawl_data</h>\n",
    "        <hr>\n",
    "        <p>This function gets the departure countries as a list, the destination countries, the departure dates, and the more_results_button for the more_button function.</p>\n",
    "        <p>We run on all of the option that can be between departure countries, destination countries and dates. For example:</p>\n",
    "        <p>depart_countries = ['israel'], destination_countries = ['italy','denmark'], date = [29/2/2022].</p>\n",
    "        <p>Our option are: israel->italy(29/2/2022),israel->denmark(29/2/2022)</p>\n",
    "        <p>Then we run for each ticket category(Chepest/Best/Quickest) for each variation the algorithm below:</p>\n",
    "        <p>step 1: open the webpage using open_web function.</p>\n",
    "        <p>step 2: load more tickets in current webpage by clicking on the 'show more results' using more_button function.</p>\n",
    "        <p>step 3: crawl and get the data from this page.</p>\n",
    "        <p>step 4: if each list of the data is the same lengh use Write_CSV function to save the collected data as a dataframe.</p>\n",
    "        <p>repeat the steps 1-4 for each variation, and restart the driver for each run (sometimes the websites wants the check if we are not robots. this prevents us from collecting the data.)</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a23803bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Crawl_data(departure_countries ,countries ,dates, more_results_button):\n",
    "    for dep_country in departure_countries:\n",
    "        for country in countries:\n",
    "            path = r'C:\\Users\\USER\\Downloads\\chromedriver_win32\\chromedriver'\n",
    "            driver = wd.Chrome(path)\n",
    "            if country!=dep_country:\n",
    "                for date in dates:\n",
    "                    for category in ['price_a','bestflight_a','duration_a']:\n",
    "                        try:\n",
    "                            time.sleep(1)\n",
    "                            open_web(dep_country, country,\n",
    "                                     date, category, driver)\n",
    "                        except:    \n",
    "                            time.sleep(3)\n",
    "                            open_web(dep_country, country,\n",
    "                                     date, category, driver)\n",
    "                        try:\n",
    "                            time.sleep(2)\n",
    "                            more_button(more_results_button, driver) \n",
    "                        except:\n",
    "                            pass\n",
    "                        try:\n",
    "                            time.sleep(2)\n",
    "                            page_info = crawl_page(driver)\n",
    "                        except:\n",
    "                            time.sleep(3)\n",
    "                            page_info = crawl_page(driver)\n",
    "                        try:\n",
    "                            for x in page_info:\n",
    "                                for y in page_info:\n",
    "                                    if(len(x)!=len(y)):\n",
    "                                        raise Exception('Wrong_Lenghts')\n",
    "                            lengh = len(page_info[0])\n",
    "                            dic = {\n",
    "                                'Airline': page_info[0],\n",
    "                                'Date':([date]*lengh),\n",
    "                                'Source_Airport': page_info[1],\n",
    "                                'Destination_Airport': page_info[2],\n",
    "                                'Route': page_info[3],\n",
    "                                'Departure_Time': page_info[4],\n",
    "                                'Arrival_Time': page_info[5],\n",
    "                                'Duration': page_info[6],\n",
    "                                'Stops_Number': page_info[7],\n",
    "                                'Price': page_info[8]\n",
    "                            }\n",
    "                            Write_CSV(dic)\n",
    "                        except:\n",
    "                            pass                        \n",
    "            driver.close()\n",
    "            time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a8756e",
   "metadata": {},
   "source": [
    "<html>\n",
    "    <body>\n",
    "        <hr>\n",
    "        <h>The main run</h>\n",
    "        <hr>\n",
    "        <p>Run this line to start selenium crawling</p>\n",
    "    </body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637e23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-ddfa8ea30e00>:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = wd.Chrome(path)\n",
      "<ipython-input-3-067ee9cc7540>:5: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  driver.find_element_by_xpath('//a[@class=\"moreButton\"]').click()\n",
      "<ipython-input-4-33f877969e6e>:4: DeprecationWarning: find_elements_by_* commands are deprecated. Please use find_elements() instead\n",
      "  element = driver.find_elements_by_xpath(xpath)\n"
     ]
    }
   ],
   "source": [
    "# 118cy = Italy, 90cy = Germany, 15cy = Austria \n",
    "# 225cy = Spain, 82cy = France, 94cy = Greece\n",
    "# 24cy = Belgium, 174cy = Netherlands\n",
    "# 252cy = UK, 65cy = Denmark\n",
    "# 233cy = Switzerland\n",
    "# 197cy = Portugal, 116cy = Ireland, 117cy = Israel\n",
    "Crawl_data(['117cy'],\n",
    "           ['118cy','90cy','15cy','225cy','82cy','94cy',\n",
    "            '24cy','174cy','252cy','65cy','116cy','233cy'], \n",
    "            ['2022-02-06','2022-02-07','2022-02-08','2022-02-09','2022-02-10'\n",
    "            ,'2022-02-11','2022-02-12','2022-03-06','2022-03-09','2022-03-12',\n",
    "            '2022-03-27','2022-03-30','2022-04-01','2022-05-06',\n",
    "            '2022-05-09','2022-05-12'], 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
